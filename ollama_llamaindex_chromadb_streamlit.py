# ollama_llamaindex_chromadb_streamlit.py
import os
import re
from typing import List

import streamlit as st
from dotenv import load_dotenv

# RAG components: LlamaIndex + Chroma + Ollama
import chromadb
from chromadb.config import Settings
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Document
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.ollama import Ollama
from llama_index.vector_stores.chroma import ChromaVectorStore

# --------- ENV & Paths ---------
load_dotenv()
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.getenv("DATA_DIR", os.path.join(BASE_DIR, "data"))
CHROMA_DIR = os.getenv("CHROMA_DIR", os.path.join(BASE_DIR, "chroma_db"))
COLLECTION_NAME = os.getenv("CHROMA_COLLECTION", "quickstart2")
EMBED_MODEL = os.getenv("EMBED_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "qwen3:0.6b")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CHROMA_DIR, exist_ok=True)

st.set_page_config(page_title="‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ (RAG)", page_icon="ü§ñ", layout="wide")
st.title("‡∏ú‡∏π‡πâ‡∏ä‡πà‡∏ß‡∏¢‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")
st.caption("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå ‚Üí ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ ‚Üí ‡∏ñ‡∏≤‡∏°‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏†‡∏≤‡∏©‡∏≤‡πÑ‡∏ó‡∏¢")

# ---------- cached resources ----------
@st.cache_resource(show_spinner=False)
def get_embed_model():
    return HuggingFaceEmbedding(model_name=EMBED_MODEL, device="cuda", trust_remote_code=True)

@st.cache_resource(show_spinner=False)
@st.cache_resource(show_spinner=False)
def get_llm():
    return Ollama(
        model=OLLAMA_MODEL,
        base_url=OLLAMA_BASE_URL,
        request_timeout=60.0,
        context_window=8192,
        num_output=512,
        additional_kwargs={
            "options": {
                "num_gpus": 1,
                "temperature": 0.4,
                "top_p": 0.9,
            }
        },
    )

def _list_data_files() -> list[str]:
    files = []
    for name in sorted(os.listdir(DATA_DIR)):
        full = os.path.join(DATA_DIR, name)
        if os.path.isfile(full):
            files.append(name)
    return files

def _ensure_sample_if_empty() -> List[Document]:
    docs = SimpleDirectoryReader(DATA_DIR).load_data()
    if not docs:
        sample_path = os.path.join(DATA_DIR, "sample.txt")
        if not os.path.exists(sample_path):
            with open(sample_path, "w", encoding="utf-8") as f:
                f.write("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡πÉ‡∏™‡πà‡πÑ‡∏ü‡∏•‡πå‡∏•‡∏á‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data/ ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î ‚Äú‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‚Äù\n")
        docs = SimpleDirectoryReader(DATA_DIR).load_data()
    return docs

def _load_docs_from_selected(selected_files: list[str]) -> List[Document]:
    if not selected_files:
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ fallback
        return _ensure_sample_if_empty()
    paths = [os.path.join(DATA_DIR, f) for f in selected_files]
    return SimpleDirectoryReader(input_files=paths).load_data()

@st.cache_resource(show_spinner=False)
def _get_chroma_client():
    return chromadb.PersistentClient(path=CHROMA_DIR, settings=Settings(anonymized_telemetry=False))

def _get_or_create_collection(chroma_client):
    try:
        return chroma_client.get_collection(COLLECTION_NAME)
    except Exception:
        return chroma_client.create_collection(COLLECTION_NAME)

@st.cache_resource(show_spinner=False)
def build_index(docs: List[Document] | None = None) -> VectorStoreIndex:
    chroma_client = _get_chroma_client()
    chroma_collection = _get_or_create_collection(chroma_client)

    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    if docs is None:
        docs = _ensure_sample_if_empty()

    index = VectorStoreIndex.from_documents(
        docs,
        embed_model=get_embed_model(),
        storage_context=storage_context,
        show_progress=True,
        batch_size=16,
    )
    return index

def clear_collection():
    chroma_client = _get_chroma_client()
    # ‡∏•‡∏ö‡∏ê‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏î‡∏¥‡∏°‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    try:
        chroma_client.delete_collection(COLLECTION_NAME)
    except Exception:
        pass
    chroma_client.create_collection(COLLECTION_NAME)

# --------- Sidebar: Files + Upload + Actions ---------
with st.sidebar:
    st.header("‡πÑ‡∏ü‡∏•‡πå‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ")

    up = st.file_uploader(
        "‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì",
        accept_multiple_files=True,
        help="‡πÑ‡∏ü‡∏•‡πå‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data/ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ"
    )
    if up:
        for f in up:
            dest = os.path.join(DATA_DIR, f.name)
            with open(dest, "wb") as out:
                out.write(f.read())
        st.success(f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î {len(up)} ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡πâ‡∏ß ‚Äî ‡∏Å‡∏î ‚Äú‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‚Äù ‡∏î‡πâ‡∏≤‡∏ô‡∏•‡πà‡∏≤‡∏á")

    st.subheader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ")

    files_in_data = _list_data_files()

    if "selected_files" not in st.session_state:
        st.session_state.selected_files = set()

    new_selected = set(st.session_state.selected_files)

    for fname in files_in_data:
        checked = fname in st.session_state.selected_files
        c = st.checkbox(fname, value=checked, key=f"file_{fname}")
        if c:
            new_selected.add(fname)
        else:
            new_selected.discard(fname)

    st.session_state.selected_files = new_selected

    st.caption(f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß {len(st.session_state.selected_files)} ‡∏à‡∏≤‡∏Å‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î {len(files_in_data)} ‡πÑ‡∏ü‡∏•‡πå")

    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    if st.button("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÉ‡∏´‡∏°‡πà‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", use_container_width=True,
                 help="‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° (‡∏ó‡∏±‡∏ö‡∏Ç‡∏≠‡∏á‡πÄ‡∏î‡∏¥‡∏°‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Ç‡πâ‡∏≠‡∏á)"):
        build_index.clear()
        st.cache_resource.clear()

        docs = _load_docs_from_selected(list(st.session_state.selected_files))
        _ = build_index(docs=docs)
        st.success("‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ ‚úÖ")

    # ‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    st.divider()
    st.markdown("### ‡∏Å‡∏≤‡∏£‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ")
    st.caption("‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏±‡∏î‡∏ó‡∏≥‡πÑ‡∏ß‡πâ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡∏•‡∏ö‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î ‡πÅ‡∏ï‡πà‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡∏¢‡∏±‡∏á‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data/")

    if st.button("‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î", use_container_width=True,
                 help="‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÑ‡∏ß‡πâ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î (‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πâ‡∏ô‡∏â‡∏ö‡∏±‡∏ö‡πÉ‡∏ô data/ ‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏•‡∏ö)"):
        clear_collection()
        build_index.clear()
        st.cache_resource.clear()
        st.success("‡∏•‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô‡∏Ñ‡∏ß‡∏≤‡∏°‡∏£‡∏π‡πâ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ üßπ")

# --------- Main Q&A ---------
question = st.text_area(
    "‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏∏‡∏ì",
    placeholder="‡πÄ‡∏ä‡πà‡∏ô \"‡∏™‡∏£‡∏∏‡∏õ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç‡∏à‡∏≤‡∏Å‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£\"",
    height=100
)
if st.button("‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö", type="primary"):
    if not question.strip():
        st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏Å‡πà‡∏≠‡∏ô")
    else:
        # ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á index
        selected_files = list(st.session_state.get("selected_files", []))
        docs = _load_docs_from_selected(selected_files)

        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
            qe = build_index(docs=docs).as_query_engine(llm=get_llm())
            resp = qe.query(question)

        st.subheader("‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö")
        # ‡πÅ‡∏õ‡∏•‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡πÄ‡∏õ‡πá‡∏ô‡∏™‡∏ï‡∏£‡∏¥‡∏á ‡πÅ‡∏•‡πâ‡∏ß‡∏•‡∏ö‡πÅ‡∏ó‡πá‡∏Å <think>...</think>
        clean_resp = re.sub(r"<think>.*?</think>", "", str(resp), flags=re.DOTALL)
        clean_resp = clean_resp.strip()
        st.write(clean_resp)

        src_nodes = getattr(resp, "source_nodes", []) or []
        st.subheader("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á")
        if not src_nodes:
            st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÅ‡∏™‡∏î‡∏á")
        else:
            for i, n in enumerate(src_nodes, 1):
                with st.expander(f"‡πÅ‡∏´‡∏•‡πà‡∏á‡∏≠‡πâ‡∏≤‡∏á‡∏≠‡∏¥‡∏á #{i} ‚Ä¢ score={getattr(n, 'score', None)}"):
                    text_preview = (n.get_text() or "")[:1000] if hasattr(n, "get_text") else ""
                    st.code(text_preview)
                    meta = getattr(n.node, "metadata", {}) if hasattr(n, "node") else {}
                    st.json(meta)
