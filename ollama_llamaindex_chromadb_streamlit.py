import os
from typing import List

import streamlit as st
from dotenv import load_dotenv

# RAG components: LlamaIndex + Chroma + Ollama
import chromadb
from chromadb.config import Settings
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext, Document
from llama_index.embeddings.huggingface import HuggingFaceEmbedding
from llama_index.llms.ollama import Ollama
from llama_index.vector_stores.chroma import ChromaVectorStore

# --------- ENV & Paths ---------
load_dotenv()
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
DATA_DIR = os.getenv("DATA_DIR", os.path.join(BASE_DIR, "data"))
CHROMA_DIR = os.getenv("CHROMA_DIR", os.path.join(BASE_DIR, "chroma_db"))
COLLECTION_NAME = os.getenv("CHROMA_COLLECTION", "quickstart2")
EMBED_MODEL = os.getenv("EMBED_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
OLLAMA_BASE_URL = os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
OLLAMA_MODEL = os.getenv("OLLAMA_MODEL", "scb10x/llama3.2-typhoon2-1b-instruct:latest")

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CHROMA_DIR, exist_ok=True)

st.set_page_config(page_title="RAG (Streamlit)", page_icon="ü§ñ", layout="wide")
st.title("RAG Web UI (Streamlit)")
st.caption("LlamaIndex + Chroma + Ollama")

# ---------- cached resources ----------
@st.cache_resource(show_spinner=False)
def get_embed_model():
    return HuggingFaceEmbedding(model_name=EMBED_MODEL, device="cuda", trust_remote_code=True)

@st.cache_resource(show_spinner=False)
def get_llm():
    return Ollama(
        model=OLLAMA_MODEL,
        base_url=OLLAMA_BASE_URL,
        request_timeout=120.0,
        additional_kwargs={"options": {"num_gpus": 1}}
    )

def _list_data_files() -> list[str]:
    files = []
    for name in sorted(os.listdir(DATA_DIR)):
        full = os.path.join(DATA_DIR, name)
        if os.path.isfile(full):
            files.append(name)
    return files

def _ensure_sample_if_empty() -> List[Document]:
    docs = SimpleDirectoryReader(DATA_DIR).load_data()
    if not docs:
        sample_path = os.path.join(DATA_DIR, "sample.txt")
        if not os.path.exists(sample_path):
            with open(sample_path, "w", encoding="utf-8") as f:
                f.write("‡∏™‡∏ß‡∏±‡∏™‡∏î‡∏µ! ‡πÉ‡∏™‡πà‡πÑ‡∏ü‡∏•‡πå‡∏•‡∏á data/ ‡πÅ‡∏•‡πâ‡∏ß‡∏Å‡∏î Rebuild Index\n")
        docs = SimpleDirectoryReader(DATA_DIR).load_data()
    return docs

def _load_docs_from_selected(selected_files: list[str]) -> List[Document]:
    if not selected_files:
        # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏•‡∏¢ ‡πÉ‡∏´‡πâ fallback
        return _ensure_sample_if_empty()
    paths = [os.path.join(DATA_DIR, f) for f in selected_files]
    return SimpleDirectoryReader(input_files=paths).load_data()

@st.cache_resource(show_spinner=False)
def _get_chroma_client():
    return chromadb.PersistentClient(path=CHROMA_DIR, settings=Settings(anonymized_telemetry=False))

def _get_or_create_collection(chroma_client):
    try:
        return chroma_client.get_collection(COLLECTION_NAME)
    except Exception:
        return chroma_client.create_collection(COLLECTION_NAME)

@st.cache_resource(show_spinner=False)
def build_index(docs: List[Document] | None = None) -> VectorStoreIndex:
    chroma_client = _get_chroma_client()
    chroma_collection = _get_or_create_collection(chroma_client)

    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    storage_context = StorageContext.from_defaults(vector_store=vector_store)

    if docs is None:
        docs = _ensure_sample_if_empty()

    index = VectorStoreIndex.from_documents(
        docs,
        embed_model=get_embed_model(),
        storage_context=storage_context,
        show_progress=True,
        batch_size=16,
    )
    return index

def clear_collection():
    chroma_client = _get_chroma_client()
    # ‡∏•‡∏ö collection ‡πÄ‡∏î‡∏¥‡∏°
    try:
        chroma_client.delete_collection(COLLECTION_NAME)
    except Exception:
        pass
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÉ‡∏´‡∏°‡πà‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ build_index ‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏ñ‡∏±‡∏î‡πÑ‡∏õ‡πÄ‡∏à‡∏≠‡πÅ‡∏ô‡πà ‡πÜ
    chroma_client.create_collection(COLLECTION_NAME)

# --------- Sidebar: Files + Upload + Actions ---------
with st.sidebar:
    st.header("‡πÑ‡∏ü‡∏•‡πå‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£")

    up = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô data/)", accept_multiple_files=True)
    if up:
        for f in up:
            dest = os.path.join(DATA_DIR, f.name)
            with open(dest, "wb") as out:
                out.write(f.read())
        st.success(f"‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î {len(up)} ‡πÑ‡∏ü‡∏•‡πå‡πÅ‡∏•‡πâ‡∏ß ‚Äî ‡∏≠‡∏¢‡πà‡∏≤‡∏•‡∏∑‡∏° Rebuild Index")

    st.subheader("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏î‡∏±‡∏ä‡∏ô‡∏µ")

    files_in_data = _list_data_files()

    if "selected_files" not in st.session_state:
        st.session_state.selected_files = set(files_in_data)

    new_selected = set(st.session_state.selected_files)

    for fname in files_in_data:
        checked = fname in st.session_state.selected_files
        c = st.checkbox(fname, value=checked, key=f"file_{fname}")
        if c:
            new_selected.add(fname)
        else:
            new_selected.discard(fname)

    st.session_state.selected_files = new_selected

    st.caption(f"‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏•‡πâ‡∏ß: {len(st.session_state.selected_files)} / {len(files_in_data)}")

    # Rebuild ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å
    if st.button("Rebuild Index ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å", use_container_width=True):
        build_index.clear()
        st.cache_resource.clear()

        docs = _load_docs_from_selected(list(st.session_state.selected_files))
        _ = build_index(docs=docs)
        st.success("Rebuild ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‚úÖ")

    # ‡∏•‡πâ‡∏≤‡∏á collection
    if st.button("‡∏•‡πâ‡∏≤‡∏á Collection (Chroma)", use_container_width=True):
        clear_collection()
        build_index.clear()
        st.cache_resource.clear()
        st.success("‡∏•‡πâ‡∏≤‡∏á Collection ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢ üßπ")

# --------- Main Q&A ---------
question = st.text_area("‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°", placeholder="‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ó‡∏µ‡πà‡∏ô‡∏µ‡πà...", height=100)
if st.button("‡∏ñ‡∏≤‡∏°", type="primary"):
    if not question.strip():
        st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
    else:
        # üü£ ‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ‡∏Ñ‡∏∑‡∏≠‡∏à‡∏∏‡∏î‡πÅ‡∏Å‡πâ‡∏™‡∏≥‡∏Ñ‡∏±‡∏ç ‚Äî ‡πÉ‡∏ä‡πâ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏°‡∏≤‡∏™‡∏£‡πâ‡∏≤‡∏á index
        selected_files = list(st.session_state.get("selected_files", []))
        docs = _load_docs_from_selected(selected_files)

        # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå build_index ‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å‡∏ö‡∏±‡∏á‡∏Ñ‡∏±‡∏ö‡πÉ‡∏´‡πâ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏à‡∏≤‡∏Å docs ‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡∏ó‡∏∏‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á‡∏Å‡πá‡πÑ‡∏î‡πâ
        # build_index.clear()

        with st.spinner("‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏™‡∏£‡∏∏‡∏õ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö..."):
            qe = build_index(docs=docs).as_query_engine(llm=get_llm())
            resp = qe.query(question)

        st.subheader("‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö")
        st.write(str(resp))

        src_nodes = getattr(resp, "source_nodes", []) or []
        st.subheader("‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤")
        if not src_nodes:
            st.caption("‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        else:
            for i, n in enumerate(src_nodes, 1):
                with st.expander(f"‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤ #{i} ‚Ä¢ score={getattr(n, 'score', None)}"):
                    text_preview = (n.get_text() or "")[:1000] if hasattr(n, "get_text") else ""
                    st.code(text_preview)
                    meta = getattr(n.node, "metadata", {}) if hasattr(n, "node") else {}
                    st.json(meta)
