# retrieve_direct.py
import os
from dotenv import load_dotenv

# ---------- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô ----------
CHROMA_DIR = "./chroma_db"
DATA_DIR = "data"
EMBED_MODEL = os.getenv("EMBED_MODEL", "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2")
TOP_K = int(os.getenv("TOP_K", 3))  # ‡∏õ‡∏£‡∏±‡∏ö‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå‡∏ó‡∏µ‡πà‡∏≠‡∏¢‡∏≤‡∏Å‡∏î‡∏π

os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CHROMA_DIR, exist_ok=True)
load_dotenv()

# ---------- ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ + ‡∏ù‡∏±‡∏á‡∏•‡∏á‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡πÇ‡∏ï‡∏£‡πå (‡∏ñ‡πâ‡∏≤‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ) ----------
from llama_index.core import SimpleDirectoryReader, VectorStoreIndex, StorageContext
from llama_index.embeddings.huggingface import HuggingFaceEmbedding

# ‡πÇ‡∏´‡∏•‡∏î‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏à‡∏≤‡∏Å‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data/
documents = SimpleDirectoryReader(DATA_DIR).load_data()
if not documents:
    raise RuntimeError("‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ô‡πÇ‡∏ü‡∏•‡πÄ‡∏î‡∏≠‡∏£‡πå data/ ‡πÉ‡∏™‡πà‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏™‡∏£‡πâ‡∏≤‡∏á data/sample.txt ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö")

# ‡∏™‡∏£‡πâ‡∏≤‡∏á embedding model (‡πÑ‡∏°‡πà‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö LLM)
embed_model = HuggingFaceEmbedding(
    model_name=EMBED_MODEL,
    trust_remote_code=True
)

# ---------- ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏° Chroma (Persistent) ----------
import chromadb
from llama_index.vector_stores.chroma import ChromaVectorStore
from chromadb.config import Settings

chroma_client = chromadb.PersistentClient(path=CHROMA_DIR, settings=Settings(anonymized_telemetry=False)) #‡πÄ‡∏õ‡∏¥‡∏î/‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ê‡∏≤‡∏ô Chroma ‡πÅ‡∏ö‡∏ö persistent
collection_name = "quickstart2"  # ‡∏ä‡∏∑‡πà‡∏≠‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Ñ‡∏ä‡∏±‡∏ô

try:
    chroma_collection = chroma_client.get_collection(collection_name)
    chroma_collection.delete(collection_name)  # ‡∏•‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡πà‡∏≤ (‡∏ñ‡πâ‡∏≤‡∏°‡∏µ) ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà

except:
    chroma_collection = chroma_client.create_collection(collection_name)

vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
storage_context = StorageContext.from_defaults(vector_store=vector_store)

# ‡∏™‡∏£‡πâ‡∏≤‡∏á/‡∏≠‡∏±‡∏õ‡πÄ‡∏î‡∏ï‡∏î‡∏±‡∏ä‡∏ô‡∏µ (‡∏ù‡∏±‡∏á‡πÄ‡∏≠‡∏Å‡∏™‡∏≤‡∏£ -> ‡πÄ‡∏Å‡πá‡∏ö‡πÉ‡∏ô Chroma)
index = VectorStoreIndex.from_documents(
    documents,
    embed_model=embed_model,
    storage_context=storage_context,
)
# (‡∏ñ‡πâ‡∏≤‡∏≠‡∏¢‡∏≤‡∏Å pure-Chroma ‡∏à‡∏£‡∏¥‡∏á ‡πÜ ‡∏ï‡πâ‡∏≠‡∏á ‡πÅ‡∏ï‡∏Å‡∏ä‡∏¥‡πâ‡∏ô‡πÄ‡∏≠‡∏á + ‡∏ù‡∏±‡∏á‡πÄ‡∏≠‡∏á ‡πÅ‡∏•‡πâ‡∏ß collection.add(ids=..., documents=..., metadatas=..., embeddings=...))

# ---------- ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 1: ‡πÉ‡∏ä‡πâ LlamaIndex Retriever ‡πÇ‡∏î‡∏¢‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LLM ----------
def retrieve_with_llamaindex(query: str, top_k: int = TOP_K):
    retriever = index.as_retriever(similarity_top_k=top_k)
    nodes = retriever.retrieve(query)
    results = []
    for rank, n in enumerate(nodes, start=1):
        results.append({
            "rank": rank,
            "score": n.score,  # ‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏Å‡∏•‡πâ
            "node_id": getattr(n, "node_id", getattr(n, "id_", None)),
            "source": n.metadata.get("file_path") or n.metadata.get("filename") or n.metadata,
            "text": n.get_content().strip()[:500]  # ‡∏ï‡∏±‡∏î‡πÅ‡∏™‡∏î‡∏á 500 ‡∏ï‡∏±‡∏ß‡∏≠‡∏±‡∏Å‡∏©‡∏£‡∏û‡∏≠‡πÉ‡∏´‡πâ‡πÄ‡∏´‡πá‡∏ô‡∏ö‡∏£‡∏¥‡∏ö‡∏ó
        })
    return results

# ---------- ‡∏ß‡∏¥‡∏ò‡∏µ‡∏ó‡∏µ‡πà 2: ‡∏Ñ‡∏¥‡∏ß‡∏£‡∏µ Chroma ‡∏ï‡∏£‡∏á ‡πÜ ----------
# (‡πÄ‡∏Ç‡πâ‡∏≤‡∏£‡∏´‡∏±‡∏™‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏î‡πâ‡∏ß‡∏¢ embed_model ‡πÅ‡∏•‡πâ‡∏ß query ‡∏ó‡∏µ‡πà‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Ñ‡∏ä‡∏±‡∏ô)
def retrieve_with_chroma(query: str, top_k: int = TOP_K):
    qvec = embed_model.get_text_embedding(query)  # ‡πÄ‡∏£‡∏≤ ‡∏ù‡∏±‡∏á‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏î‡πâ‡∏ß‡∏¢‡πÇ‡∏°‡πÄ‡∏î‡∏•‡πÄ‡∏î‡∏µ‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏ï‡∏≠‡∏ô ingest
    out = chroma_collection.query(
        query_embeddings=[qvec],
        n_results=top_k,
        include=["documents", "metadatas", "distances", "embeddings"]  # embeddings ‡πÑ‡∏°‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡πá‡πÑ‡∏î‡πâ  include ‡∏Ñ‡∏∑‡∏≠‡∏û‡∏≤‡∏£‡∏≤‡∏°‡∏¥‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏ó‡∏µ‡πà‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤ ‚Äú‡∏≠‡∏¢‡∏≤‡∏Å‡πÉ‡∏´‡πâ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå ‡∏Ñ‡∏∑‡∏ô‡∏ü‡∏¥‡∏•‡∏î‡πå‡∏≠‡∏∞‡πÑ‡∏£‡∏ö‡πâ‡∏≤‡∏á‚Äù
    )
# Chroma ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏£‡∏∞‡∏¢‡∏∞/‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ ‡∏î‡πâ‡∏ß‡∏¢ metric ‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏≠‡∏•‡πÄ‡∏•‡∏Å‡∏ä‡∏±‡∏ô (‡∏õ‡∏Å‡∏ï‡∏¥ ‚Äúcosine‚Äù) ‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡∏Å‡∏•‡∏±‡∏ö:
# documents: ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡πÅ‡∏ï‡πà‡∏•‡∏∞‡∏ä‡∏¥‡πâ‡∏ô
# metadatas: ‡πÄ‡∏°‡∏ó‡∏≤‡∏î‡∏≤‡∏ó‡∏≤‡∏Ç‡∏≠‡∏á‡∏ä‡∏¥‡πâ‡∏ô
# ids: ‡πÑ‡∏≠‡∏î‡∏µ‡∏Ç‡∏≠‡∏á‡∏ä‡∏¥‡πâ‡∏ô
# distances: ‡∏£‡∏∞‡∏¢‡∏∞ (‡∏ñ‡πâ‡∏≤ cosine ‚Üí ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢)
    
    # ‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏: Chroma ‡πÉ‡∏´‡πâ‡∏Ñ‡πà‡∏≤ "distances" (‡∏¢‡∏¥‡πà‡∏á‡∏ô‡πâ‡∏≠‡∏¢‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ ‡∏ñ‡πâ‡∏≤‡πÉ‡∏ä‡πâ cosine distance)
    results = []
    docs = out.get("documents", [[]])[0]
    metas = out.get("metadatas", [[]])[0]
    dists = out.get("distances", [[]])[0]
    # emb = out.get("embeddings", [[]])[0] # ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Å‡πá‡πÑ‡∏î‡πâ
    for i, (doc, meta, dist) in enumerate(zip(docs, metas, dists), start=1):
        results.append({
            "rank": i,
            "distance": dist,  # ‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ (‡∏õ‡∏Å‡∏ï‡∏¥‡πÄ‡∏õ‡πá‡∏ô cosine distance)
            "source": (meta.get("file_path") or meta.get("filename") or meta),
            "text": (doc or "")[:500],
            # "embedding": emb[i-1],  # ‡∏≠‡∏±‡∏ô‡∏ô‡∏µ‡πâ‡πÑ‡∏°‡πà‡∏ï‡πâ‡∏≠‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Å‡πá‡πÑ‡∏î‡πâ
        })
    return results

# ---------- CLI ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏´‡∏°‡∏î ----------
def pretty_print(title: str, rows: list[dict]):
    print("\n" + "="*8 + f" {title} " + "="*8)
    if not rows:
        print("(no results)")
        return
    for r in rows:
        if "score" in r:
            head = f"[{r['rank']}] score={r['score']:.4f} ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢ (‡∏¢‡∏¥‡πà‡∏á‡∏™‡∏π‡∏á‡∏¢‡∏¥‡πà‡∏á‡πÉ‡∏Å‡∏•‡πâ)"
        else:
            head = f"[{r['rank']}] distance={r['distance']:.4f} ‡∏£‡∏∞‡∏¢‡∏∞ (‡∏™‡πà‡∏ß‡∏ô‡πÉ‡∏´‡∏ç‡πà‡πÄ‡∏õ‡πá‡∏ô cosine) (‡∏¢‡∏¥‡πà‡∏á‡∏ï‡πà‡∏≥‡∏¢‡∏¥‡πà‡∏á‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢)"
        print(head)
        print(f"source: {r['source']}")
        print(f"text  : {r['text']}\n")

if __name__ == "__main__":
    print("‡πÇ‡∏´‡∏°‡∏î‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡∏î‡∏∂‡∏á‡∏à‡∏≤‡∏Å‡πÄ‡∏ß‡∏Å‡πÄ‡∏ï‡∏≠‡∏£‡πå‡∏™‡πÇ‡∏ï‡∏£‡πå‡πÇ‡∏î‡∏¢ '‡πÑ‡∏°‡πà‡πÉ‡∏ä‡πâ LLM'")
    print("‡∏û‡∏¥‡∏°‡∏û‡πå‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏•‡πâ‡∏ß‡∏î‡∏π‡∏ú‡∏•‡∏à‡∏≤‡∏Å 2 ‡∏ß‡∏¥‡∏ò‡∏µ (LlamaIndex Retriever / Chroma Query)")
    print("‡∏Å‡∏î Ctrl+C ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏≠‡∏≠‡∏Å\n")
    while True:
        try:
            q = input("‡∏ñ‡∏≤‡∏°‡∏≠‡∏∞‡πÑ‡∏£‡∏î‡∏µ: ").strip()
            if not q:
                continue

            li = retrieve_with_llamaindex(q, TOP_K)
            pretty_print("LlamaIndex Retriever (no LLM)", li)

            ch = retrieve_with_chroma(q, TOP_K)
            pretty_print("Chroma Direct Query", ch)
        except KeyboardInterrupt:
            print("\n‡∏ö‡∏≤‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö üëã")
            break
